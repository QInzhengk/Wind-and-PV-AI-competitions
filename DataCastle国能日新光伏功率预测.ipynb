{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time \n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.dates as mdate\n",
    "import matplotlib\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus']=False  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36912194",
   "metadata": {},
   "source": [
    "# STEP0:导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "         数据包括四个站点的训练数据：train_1,train_2,train_3,train_4\n",
    "         以及四个站点的测试数据:test_1,test_2,test_3,test_4\n",
    "         参数：数据集文件所在的路径\n",
    "  \n",
    "\"\"\"\n",
    "def GetData(data_path):\n",
    "    print(\"Get Data Start\")\n",
    "    train_1=pd.read_csv(data_path+\"train_1.csv\")\n",
    "    train_2=pd.read_csv(data_path+\"train_2.csv\")\n",
    "    train_3=pd.read_csv(data_path+\"train_3.csv\")\n",
    "    train_4=pd.read_csv(data_path+\"train_4.csv\")\n",
    "\n",
    "    test_1=pd.read_csv(data_path+\"test_1.csv\")\n",
    "    test_2=pd.read_csv(data_path+\"test_2.csv\")\n",
    "    test_3=pd.read_csv(data_path+\"test_3.csv\")\n",
    "    test_4=pd.read_csv(data_path+\"test_4.csv\")\n",
    "    print(\"Get Data End\")\n",
    "    return train_1,train_2,train_3,train_4,test_1,test_2,test_3,test_4\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58a369",
   "metadata": {},
   "source": [
    "# STEP1:认识数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "      (1)各个字段基本信息（包括数据数量、数据类型、分位数均值基本统计特征）\n",
    "      (3)查看目标变量的时间周期性\n",
    "      (4)查看目标变量与其他字段的相关关系\n",
    "\n",
    "\"\"\"\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "matplotlib.style.use(\"ggplot\")\n",
    "color1=dict(boxes='DarkGreen', whiskers='DarkOrange',medians='DarkBlue', caps='Gray')\n",
    "\n",
    "def DataExploration(data1,station):\n",
    "    data=data1.copy()     \n",
    "    print(data.info())\n",
    "    print(data.describe())\n",
    "    \n",
    "    #查看各连续变量的概率分布图以及箱线图\n",
    "    data[\"实际功率\"].plot.box(color=color1)\n",
    "    plt.title(station)\n",
    "    plt.show()\n",
    "    #添加hour新字段\n",
    "    data['hour']=data['时间'].apply(lambda x:int(str(x).split(\" \")[1].split(\":\")[0]))\n",
    "    \n",
    "    #查看目标变量的时间周期性  \n",
    "    data.loc[:2000,\"实际功率\"].plot(color=\"DarkGreen\",fontsize=0.7)\n",
    "    plt.title(station+\"目标变量的时间趋势\")\n",
    "    plt.show()\n",
    "    \n",
    "    data.plot(x=\"hour\",y=\"实际功率\",kind=\"scatter\",color=\"DarkGreen\",fontsize=0.5)\n",
    "    plt.title(station+\"目标变量在各小时上的时间分布\")\n",
    "    plt.show()   \n",
    "        \n",
    "    #查看目标变量与其他字段的相关关系\n",
    "    for i in data.columns[1:8]:\n",
    "        sns.jointplot(i,\"实际功率\",data,kind=\"reg\",color=\"DarkGreen\")\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "#查看站点三的离群点值\n",
    "def  DataExploration2(data1):\n",
    "    data=data1.copy()\n",
    "    data['hour']=data['时间'].apply(lambda x:int(str(x).split(\" \")[1].split(\":\")[0]))\n",
    "    sns.countplot(data[data[\"实际功率\"]>30.13125][\"hour\"],color=\"DarkGreen\")\n",
    "    plt.title(\"train_3实际功率离群点对应的时间\",fontsize=10)\n",
    "    plt.show()\n",
    "    strange=data[data[\"实际功率\"]>=30.13125][\"实发辐照度\"].rename(\"异常值对应的实发辐照度\")\n",
    "    normal=data[data[\"实际功率\"]<30.13125][\"实发辐照度\"].rename(\"正常值对应的实发辐照度\")\n",
    "    sns.kdeplot(strange,color=\"DarkGreen\")\n",
    "    sns.kdeplot(normal,color='Red')\n",
    "    plt.title(\"train_3实发辐照度分布\",fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP2：数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   (1)删除重复值\n",
    "  （2）删除实发辐照度异常的值\n",
    "   (3) 删除站点2和站点3的异常值\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "def DataProcessing1(data,name):\n",
    "    data1=data.copy()\n",
    "    data1['hour']=data1['时间'].apply(lambda x:int(str(x).split(\" \")[1].split(\":\")[0]))\n",
    "    print(\"Data Preprocessing Start\")\n",
    "    #删除重复值\n",
    "    data1=data1.drop_duplicates()\n",
    "    \n",
    "    #将实发辐照度异常的数据删除\n",
    "    data1=data1[data1['实发辐照度'] >= 0]\n",
    "    \n",
    "    #将站点1中的离群值删除\n",
    "    if name==\"station_1\":\n",
    "        data1=data1[data1[\"实际功率\"]<10.4853]    \n",
    "    # 将站点3中实发辐照度小于600，实际功率大于30.13125的值删除\n",
    "    if name==\"station_3\":\n",
    "        data1=data1[~((data1[\"实发辐照度\"]<600)&(data1[\"实际功率\"]>=30.13125))]\n",
    "    \n",
    "    #将站点2和站点3的异常值删除\n",
    "    if name==\"station_2\":\n",
    "        a=[0,1,2,3,4,5,20,21,22,23]\n",
    "        data1=data1[~((data1.hour.isin(a))&(data1.实际功率==4.4))]\n",
    "    if name==\"station_3\":\n",
    "        a=[0,1,2,3,4,5,6,7,8,17,18,19,20,21,22,23]\n",
    "        data1=data1[~((data1.hour.isin(a))&(data1.实际功率==29.667))]\n",
    "            \n",
    "    #将train_1的时间减少1秒\n",
    "    if name==\"station_1\":\n",
    "        print(\"站点一的时间处理开始\")\n",
    "        a=datetime.timedelta(seconds=1)\n",
    "        data1[\"时间\"]=pd.to_datetime(data1[\"时间\"])-a  \n",
    "    \n",
    "    return data1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ea43a",
   "metadata": {},
   "source": [
    "# STEP3:预测实发辐照度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGBModel(x_train, y_train,x_test,y_test):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)  \n",
    "    print(\"Model Trainning Start\")\n",
    "    params = {\n",
    "      'task': 'train',\n",
    "      'boosting_type': 'gbdt',  #dart bad\n",
    "      'objective': 'regression_l1', \n",
    "      'metric': 'l1', \n",
    "      'num_leaves': 23,#22,23better,25bad\n",
    "      'learning_rate': 0.05,  # 学习速率0.05,0.04bad,0.06bad\n",
    "      'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "      'bagging_fraction': 0.8, # 建树的样本采样比例\n",
    "      'bagging_freq': 10,  # k 意味着每 k 次迭代执行bagging\n",
    "      'num_threads':1\n",
    "    }\n",
    "    gbm = lgb.train(params,lgb_train,num_boost_round=3500,valid_sets=lgb_eval,verbose_eval=1000)\n",
    "    print('Start predicting...')\n",
    "    y_pred = gbm.predict(x_test)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f7bc6",
   "metadata": {},
   "source": [
    "# STEP4:特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15286054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    FeatureCreation1:\n",
    "   （1）创建时间相关特征：month、day、hour、白天\n",
    "   （2）辐照度、温度、湿度字段的每天mean、std、白天最大值、白天最小值、最大值最小值的差\n",
    "   （3）将辐照度、温度、湿度、压强四个字段分段并转化为分类变量\n",
    "\n",
    "\"\"\"\n",
    "def FeatureCreation1(data1):\n",
    "    \n",
    "    data=data1.copy()\n",
    "    #根据时间字段创建hour、month等特征\n",
    "    data[\"month\"]=data[\"时间\"].apply(lambda x: int(str(x).split(\" \")[0].split(\"-\")[1]))\n",
    "    data[\"hour\"]=data[\"时间\"].apply(lambda x:int(str(x).split(\" \")[1].split(\":\")[0]))\n",
    "    data[\"day\"]=data[\"时间\"].apply(lambda x:int(str(x).split(\" \")[0].replace(\"-\",\"\")))\n",
    "    data[\"白天\"]=data[\"hour\"].apply(lambda x:1 if x in range(7,20) else 0)    \n",
    "    data=data.drop([\"时间\"],axis=1)\n",
    "    \n",
    "    #每天的辐照度，温度，湿度的mean，std特征\n",
    "    columns=['辐照度','温度','湿度',\"压强\"]\n",
    "    for col in columns:\n",
    "        print(\"Create\" + col +\"_mean and std...\")\n",
    "        data[col+'_mean']=data.groupby('day')[col].transform('mean')\n",
    "        data[col+'_std']=data.groupby('day')[col].transform('std')\n",
    "        data[col+\"_max\"]=data.groupby([\"day\",\"白天\"])[col].transform(\"max\")\n",
    "        data[col+\"_min\"]=data.groupby([\"day\",\"白天\"])[col].transform(\"min\")\n",
    "        data[col+\"_白天差\"]=data[col+\"_max\"]-data[col+\"_min\"] \n",
    "        print(\"Create\"+ col +\"feature end\")\n",
    "   \n",
    "    #创造其他特征——对分类变量进行one-hot编码\n",
    "    Temp = pd.get_dummies(pd.cut(data['温度'],3),prefix = 'temp') \n",
    "    Temp_split = pd.DataFrame(np.argmax(Temp.values,axis = 1)).rename(columns={0: \"temp_split\"})\n",
    "    data[\"temp_split\"] = Temp_split.temp_split.values\n",
    "    \n",
    "    Pres = pd.get_dummies(pd.cut(data['压强'],3),prefix = 'pres') \n",
    "    Pres_split = pd.DataFrame(np.argmax(Pres.values,axis = 1)).rename(columns={0: \"pres_split\"})\n",
    "    data[\"pres_split\"] = Pres_split.pres_split.values\n",
    "    \n",
    "    Humi = pd.get_dummies(pd.cut(data['湿度'],3),prefix = 'humi') \n",
    "    Humi_split = pd.DataFrame(np.argmax(Humi.values,axis = 1)).rename(columns={0: \"humi_split\"})\n",
    "    data[\"humi_split\"] = Humi_split.humi_split.values\n",
    "    \n",
    "    H = pd.get_dummies(pd.cut(data['辐照度'],5),prefix = 'temp') \n",
    "    H_split = pd.DataFrame(np.argmax(H.values,axis = 1)).rename(columns={0: \"h_split\"})\n",
    "    data[\"H_split\"] = H_split.h_split.values\n",
    "    return data\n",
    "\n",
    "def FeatureCreation2(data1):\n",
    "     \n",
    "    data=data1.copy()\n",
    "    #创造业务相关特征：包括风向风力特征和温度特征压强\n",
    "    data[\"sin_wind_d\"]=np.sin(data.风向.values * np.pi / 180.)*(data.风速.values)\n",
    "    data['cos_wind_d'] = np.cos(data.风向.values * np.pi / 180.)*(data.风速.values)\n",
    "    \n",
    "    data['temp_pressure'] = (data.压强.values+1.1)/(data.温度.values+1.1)\n",
    "    data['temp_humi'] = (data.温度.values+1.1)/(data.湿度.values+1.1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def FeatureCreation3(data1):\n",
    "    \n",
    "    data=data1.copy()\n",
    "    #使用前一时刻的对应字段值作为特征\n",
    "    temp = list(data['实发辐照度'])\n",
    "    temp = [-1.0] + [-1.0] +[-1.0] + temp + [-1.0] + [-1.0] +[-1.0]\n",
    "    data['before_f'] = np.array(temp[2:-4])\n",
    "    data['before_f1'] = np.array(temp[1:-5])\n",
    "    data['before_f2'] = np.array(temp[:-6])\n",
    "    temp1=list(data[\"温度\"])\n",
    "    temp1 =[-1.0] + [-1.0] +[-1.0]+ temp1 +[-1.0] + [-1.0] +[-1.0]\n",
    "    data['temp_before_f'] = np.array(temp1[2:-4])\n",
    "    data['temp_before_f1'] = np.array(temp1[1:-5])\n",
    "    data['temp_before_f2'] = np.array(temp1[:-6])\n",
    "    temp2=list(data[\"湿度\"])\n",
    "    temp2 =[-1.0] + [-1.0] +[-1.0]+ temp2 + [-1.0] + [-1.0] +[-1.0]\n",
    "    data['humi_before_f'] = np.array(temp2[2:-4])\n",
    "    data['humi_before_f1'] = np.array(temp2[1:-5])\n",
    "    data['humi_before_f2'] = np.array(temp2[:-6])\n",
    "    temp3=list(data[\"辐照度\"])\n",
    "    temp3 = [-1.0] + [-1.0] +[-1.0] + temp3 + [-1.0] + [-1.0] +[-1.0]\n",
    "    data['irr_before_f'] = np.array(temp3[2:-4])\n",
    "    data['irr_before_f1'] = np.array(temp3[1:-5])\n",
    "    data['irr_before_f2'] = np.array(temp3[:-6])\n",
    "    temp4=list(data[\"风速\"])\n",
    "    temp4 = [-1.0] + [-1.0] +[-1.0] + temp4 + [-1.0] + [-1.0] +[-1.0]\n",
    "    data['speed_before_f'] = np.array(temp4[2:-4])\n",
    "    data['spedd_before_f1'] = np.array(temp4[1:-5])\n",
    "    data['speed_before_f2'] = np.array(temp4[:-6])\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e201f",
   "metadata": {},
   "source": [
    "# STEP5:模型优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671aef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    用梯度搜索方法调参，找到模型的最优参数\n",
    "    参数：model代表模型，params代表用于梯度搜索的参数范围；\n",
    "\"\"\"\n",
    "def ModelOptimization(model, params, x_train, y_train):\n",
    "    print(\"Model Optimizatioin Start\")\n",
    "    #x_train = x_train.fillna(0)\n",
    "    best_params = []\n",
    "    for param in params:\n",
    "        print(\"Optimize param\", param, \"...\")\n",
    "        cv = GridSearchCV(estimator = model, param_grid = param, scoring = \"neg_mean_absolute_error\", cv = 3, n_jobs = -1)\n",
    "        cv.fit(x_train, y_train)\n",
    "        best_params.append(cv.best_params_)\n",
    "    print(\"Model Optimizatioin Done\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e992181",
   "metadata": {},
   "source": [
    "# STEP6:模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "  通过交叉验证评估模型\n",
    "  score函数参数：y_pred是预测的y值，y是含有day属性的真实标签值，name是指站点一、二、三、四\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def scorey(y_pred,y,name):\n",
    "    y[\"y_pred\"]=y_pred\n",
    "    d=y\n",
    "    if name==\"y_station1\":\n",
    "        d=d[d[\"y_pred\"]>10*0.03]\n",
    "    if name==\"y_station2\":\n",
    "        d=d[d[\"y_pred\"]>10*0.03]\n",
    "    if name==\"y_station3\":\n",
    "        d=d[d[\"y_pred\"]>40*0.03]\n",
    "    if name==\"y_station4\":\n",
    "        d=d[d[\"y_pred\"]>50*0.03]\n",
    "    mae_d=d.groupby(\"day\").apply(lambda x:(abs(x['y_pred']-x[\"实际功率\"])/10).mean()).reset_index()\n",
    "    mae_d.columns=[\"day\",\"mae_d\"]\n",
    "    b=mae_d\n",
    "    b[\"month\"]=mae_d[\"day\"].apply(lambda x:int(str(x)[:6]))\n",
    "    b=b.drop(\"day\",axis=1)\n",
    "    mae_m=b.groupby(\"month\")[\"mae_d\"].apply(lambda x:x.mean()).reset_index()\n",
    "    mae_m.columns=[\"month\",\"mae_m\"]\n",
    "    mae_mmean=mae_m[\"mae_m\"].mean()\n",
    "    return mae_mmean\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  记录验证的得分以及对应的模型\n",
    "\n",
    "\"\"\"\n",
    "def record(x_train,model,mae_score):\n",
    "    print(\"Record Start\")\n",
    "    with open(\"../Records/Records.txt\", \"a\") as f:\n",
    "        f.write(\"features:\\t\")\n",
    "        f.write(\"[\" + \", \".join(x_train.columns.values) + \"]\")\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"model:\\t\")\n",
    "        f.write(str(model))\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"mae_score:\\t\")\n",
    "        f.write(str(mae_score))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"#\" * 100)\n",
    "        f.write(\"\\n\")\n",
    "    print(\"Record Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce5113",
   "metadata": {},
   "source": [
    "导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca56065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据\n",
    "t_get_data_start=time.time()\n",
    "train_1,train_2,train_3,train_4,test_1,test_2,test_3,test_4=GetData(\"../Data/\")\n",
    "t_get_data_end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "站点一预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f07c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据探索\n",
    "\n",
    "#DataExploration(train_1,\"station_1\")\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "train_1_new=DataProcessing1(train_1,\"station_1\")\n",
    "\n",
    "#预测实发辐照度\n",
    "t_predict_shifa_start = time.time()\n",
    "train_shifa_x=train_1_new[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "train_shifa_x[\"month\"]=train_shifa_x[\"时间\"].apply(lambda x: int(str(x).split(\" \")[0].split(\"-\")[1]))\n",
    "train_shifa_x[\"hour\"]=train_shifa_x[\"时间\"].apply(lambda x:int(str(x).split(\" \")[1].split(\":\")[0]))\n",
    "train_shifa_x=train_shifa_x.drop([\"时间\"],axis=1)\n",
    "train_shifa_y=train_1_new[\"实发辐照度\"]\n",
    "test_shifa_x=test_1[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "test_shifa_x[\"month\"]=test_shifa_x[\"时间\"].apply(lambda x: int(x.split(\" \")[0].split(\"-\")[1]))\n",
    "test_shifa_x[\"hour\"]=test_shifa_x[\"时间\"].apply(lambda x:int(x.split(\" \")[1].split(\":\")[0]))\n",
    "test_shifa_x=test_shifa_x.drop([\"时间\"],axis=1)\n",
    "test_1[\"实发辐照度\"]=0\n",
    "test_shifa_y=test_1.pop(\"实发辐照度\")\n",
    "\n",
    "test_shifa_y=LGBModel(train_shifa_x,train_shifa_y,test_shifa_x,test_shifa_y)\n",
    "test_1[\"实发辐照度\"]=test_shifa_y\n",
    "\n",
    "\n",
    "#特征工程\n",
    "\n",
    "\n",
    "train_1_y=train_1_new.pop(\"实际功率\")\n",
    "train_1_feature1=FeatureCreation1(train_1_new)\n",
    "train_1_feature2=FeatureCreation2(train_1_feature1)\n",
    "train_1_feature3=FeatureCreation3(train_1_feature2)\n",
    "test_1_id=test_1.pop(\"id\")\n",
    "test_1_feature1=FeatureCreation1(test_1)\n",
    "test_1_feature2=FeatureCreation2(test_1_feature1)\n",
    "test_1_feature3=FeatureCreation3(test_1_feature2)\n",
    "\n",
    "train_1_feature1=train_1_feature1.reset_index().drop([\"index\"],axis=1)\n",
    "train_1_y=train_1_y.reset_index().drop([\"index\"],axis=1)\n",
    "train_1_y[\"day\"]=train_1_feature1.pop(\"day\")\n",
    "train_1_feature1=train_1_feature1.fillna(0)\n",
    "\n",
    "#模型优化（特征工程第一次）\n",
    "\n",
    "#Ridge_params=[{\"alpha\":[0.1,1,2,5,10]}]\n",
    "#scaler=StandardScaler()\n",
    "#train_1_ridge=scaler.fit_transform(train_1_feature1.values)\n",
    "#Ridge_best_params = ModelOptimization(Ridge(), Ridge_params, train_1_ridge, train_1_y[\"实际功率\"])\n",
    "\n",
    "#xgb_params = [{\"learning_rate\": [0.01,0.02, 0.05, 0.1, 0.3, 1.0]}, \n",
    "#               {\"reg_lambda\":[0.05,0.1,1,2,10]},\n",
    "#              {\"n_estimators\": [100, 150,200,250,300, 400,500]}, \n",
    "#              {\"max_depth\": range(3,10,2)}, \n",
    "#               {\"min_child_weight\": range(1,6,1)}, \n",
    "#               {\"gamma\": [i/10.0 for i in range(0,5)]}, \n",
    "#               {\"subsample\": [i/10.0 for i in range(6,10)]},\n",
    "#               {\"colsample_bytree\": [i/10.0 for i in range(5,10)]}, \n",
    "#               {\"reg_alpha\": [1e-5, 1e-2, 0.1, 100]}]\n",
    "#xgb_best_params = ModelOptimization(XGBRegressor(), xgb_params, train_1_feature1, train_1_y[\"实际功率\"])\n",
    "\n",
    "#模型评估（特征工程第一次）\n",
    "train_1_x,test_1_x,train_1_y_new,test_1_y=train_test_split(train_1_feature1,train_1_y,test_size=0.2,random_state=0)\n",
    "\n",
    "ridge=Ridge(alpha=10)\n",
    "scaler = StandardScaler()\n",
    "train_1_ridge_x = scaler.fit_transform(train_1_x.values)\n",
    "test_1_ridge_x = scaler.transform(test_1_x.values)\n",
    "ridge.fit(train_1_ridge_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_ridge =ridge.predict(test_1_ridge_x)\n",
    "ridge_mae_score=scorey(y_pred_ridge,test_1_y,\"station_1\")\n",
    "record(train_1_feature1, ridge,ridge_mae_score)\n",
    "\n",
    "ridgecv = RidgeCV(alphas=np.arange(0.1,10,0.1))\n",
    "ridgecv.fit(train_1_ridge_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_ridgecv=ridgecv.predict(test_1_ridge_x)\n",
    "ridgecv_mae_score=scorey(y_pred_ridgecv,test_1_y,\"station_1\")\n",
    "record(train_1_feature1, ridgecv,ridgecv_mae_score)\n",
    "\n",
    "xgb = XGBRegressor(n_estimators = 100, learning_rate = 0.1, max_depth = 5, min_child_weight = 5, \n",
    "                    gamma = 0.4, subsample = 0.9, colsample_bytree = 0.8, reg_alpha = 0.1)\n",
    "xgb.fit(train_1_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_xgb=xgb.predict(test_1_x)\n",
    "xgb_mae_score= scorey(y_pred_xgb,test_1_y,\"station_1\")\n",
    "record(train_1_feature1, xgb,xgb_mae_score)\n",
    "\n",
    "#模型优化（特征工程第二次）\n",
    "#train_1_feature2=train_1_feature2.fillna(0)\n",
    "#train_1_feature2=train_1_feature2.drop([\"day\"],axis=1)\n",
    "\n",
    "#Ridge_params=[{\"alpha\":[0.1,1,2,5,10]}]\n",
    "#scaler=StandardScaler()\n",
    "#train_1_ridge=scaler.fit_transform(train_1_feature2.values)\n",
    "#Ridge_best_params = ModelOptimization(Ridge(), Ridge_params, train_1_ridge, train_1_y[\"实际功率\"])\n",
    "\n",
    "#xgb_params = [{\"learning_rate\": [0.01,0.02, 0.05, 0.1, 0.3, 1.0]}, \n",
    "#               {\"reg_lambda\":[0.05,0.1,1,2,10]},\n",
    "#              {\"n_estimators\": [100, 150,200,250,300, 400,500]}, \n",
    "#              {\"max_depth\": range(3,10,2)}, \n",
    "#               {\"min_child_weight\": range(1,6,1)}, \n",
    "#               {\"gamma\": [i/10.0 for i in range(0,5)]}, \n",
    "#               {\"subsample\": [i/10.0 for i in range(6,10)]},\n",
    "#               {\"colsample_bytree\": [i/10.0 for i in range(5,10)]}, \n",
    "#               {\"reg_alpha\": [1e-5, 1e-2, 0.1, 100]}]\n",
    "#xgb_best_params = ModelOptimization(XGBRegressor(), xgb_params, train_1_feature2, train_1_y[\"实际功率\"])\n",
    "\n",
    "#模型评估（特征工程第二次）\n",
    "train_1_x,test_1_x,train_1_y_new,test_1_y=train_test_split(train_1_feature2,train_1_y,test_size=0.2,random_state=0)\n",
    "ridge=Ridge(alpha=10)\n",
    "scaler = StandardScaler()\n",
    "train_1_ridge_x = scaler.fit_transform(train_1_x.values)\n",
    "test_1_ridge_x = scaler.transform(test_1_x.values)\n",
    "ridge.fit(train_1_ridge_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_ridge =ridge.predict(test_1_ridge_x)\n",
    "ridge_mae_score=scorey(y_pred_ridge,test_1_y,\"station_1\")\n",
    "record(train_1_feature1, ridge,ridge_mae_score)\n",
    "\n",
    "ridgecv = RidgeCV(alphas=np.arange(0.1,10,0.1))\n",
    "ridgecv.fit(train_1_ridge_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_ridgecv=ridgecv.predict(test_1_ridge_x)\n",
    "ridgecv_mae_score=scorey(y_pred_ridgecv,test_1_y,\"station_1\")\n",
    "record(train_1_feature1, ridgecv,ridgecv_mae_score)\n",
    "\n",
    "xgb = XGBRegressor(n_estimators = 100, learning_rate = 0.1, max_depth = 7, min_child_weight = 5, \n",
    "                    gamma = 0.4, subsample = 0.9, colsample_bytree = 0.8, reg_alpha = 0.1)\n",
    "xgb.fit(train_1_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_xgb=xgb.predict(test_1_x)\n",
    "xgb_mae_score= scorey(y_pred_xgb,test_1_y,\"station_1\")\n",
    "record(train_1_feature2, xgb,xgb_mae_score)\n",
    "\n",
    "\n",
    "#模型优化（特征工程第三次）\n",
    "#train_1_feature3=train_1_feature3.fillna(0)\n",
    "#train_1_feature3=train_1_feature3.drop([\"day\"],axis=1)\n",
    "\n",
    "#Ridge_params=[{\"alpha\":[0.1,1,2,5,10]}]\n",
    "#scaler=StandardScaler()\n",
    "#train_1_ridge=scaler.fit_transform(train_1_feature3.values)\n",
    "#Ridge_best_params = ModelOptimization(Ridge(), Ridge_params, train_1_ridge, train_1_y[\"实际功率\"])\n",
    "\n",
    "#xgb_params = [{\"learning_rate\": [0.01,0.02, 0.05, 0.1, 0.3, 1.0]}, \n",
    "#               {\"reg_lambda\":[0.05,0.1,1,2,10]},\n",
    "#              {\"n_estimators\": [100, 150,200,250,300, 400,500]}, \n",
    "#              {\"max_depth\": range(3,10,2)}, \n",
    "#               {\"min_child_weight\": range(1,6,1)}, \n",
    "#               {\"gamma\": [i/10.0 for i in range(0,5)]}, \n",
    "#               {\"subsample\": [i/10.0 for i in range(6,10)]},\n",
    "#               {\"colsample_bytree\": [i/10.0 for i in range(5,10)]}, \n",
    "#               {\"reg_alpha\": [1e-5, 1e-2, 0.1, 100]}]\n",
    "#xgb_best_params = ModelOptimization(XGBRegressor(), xgb_params, train_1_feature3, train_1_y[\"实际功率\"])\n",
    "\n",
    "#模型评估（特征工程第三次）\n",
    "train_1_x,test_1_x,train_1_y_new,test_1_y=train_test_split(train_1_feature3,train_1_y,test_size=0.2,random_state=0)\n",
    "ridge=Ridge(alpha=10)\n",
    "scaler = StandardScaler()\n",
    "train_1_ridge_x = scaler.fit_transform(train_1_x.values)\n",
    "test_1_ridge_x = scaler.transform(test_1_x.values)\n",
    "ridge.fit(train_1_ridge_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_ridge =ridge.predict(test_1_ridge_x)\n",
    "ridge_mae_score=scorey(y_pred_ridge,test_1_y,\"station_1\")\n",
    "record(train_1_feature1, ridge,ridge_mae_score)\n",
    "\n",
    "ridgecv = RidgeCV(alphas=np.arange(0.1,10,0.1))\n",
    "ridgecv.fit(train_1_ridge_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_ridgecv=ridgecv.predict(test_1_ridge_x)\n",
    "ridgecv_mae_score=scorey(y_pred_ridgecv,test_1_y,\"station_1\")\n",
    "record(train_1_feature1, ridgecv,ridgecv_mae_score)\n",
    "\n",
    "\n",
    "xgb = XGBRegressor(n_estimators = 100, learning_rate = 0.1, max_depth = 7, min_child_weight = 2, \n",
    "                    gamma = 0.4, subsample = 0.9, colsample_bytree = 0.9, reg_alpha = 0.1)\n",
    "xgb.fit(train_1_x,train_1_y_new[\"实际功率\"])\n",
    "y_pred_xgb=xgb.predict(test_1_x)\n",
    "xgb_mae_score= scorey(y_pred_xgb,test_1_y,\"station_1\")\n",
    "record(train_1_feature3, xgb,xgb_mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "站点二预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据探索\n",
    "#DataExploration(train_2)\n",
    "\n",
    "#数据预处理\n",
    "train_2_new=DataProcessing1(train_2,\"station_2\")\n",
    "#预测实发辐照度\n",
    "train_2_shifa_x=train_2_new[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "train_2_shifa_x[\"month\"]=train_2_shifa_x[\"时间\"].apply(lambda x: int(x.split(\" \")[0].split(\"-\")[1]))\n",
    "train_2_shifa_x[\"hour\"]=train_2_shifa_x[\"时间\"].apply(lambda x:int(x.split(\" \")[1].split(\":\")[0]))\n",
    "train_2_shifa_x=train_2_shifa_x.drop([\"时间\"],axis=1)\n",
    "train_2_shifa_y=train_2_new[\"实发辐照度\"]\n",
    "\n",
    "test_2_shifa_x=test_2[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "test_2_shifa_x[\"month\"]=test_2_shifa_x[\"时间\"].apply(lambda x: int(x.split(\" \")[0].split(\"-\")[1]))\n",
    "test_2_shifa_x[\"hour\"]=test_2_shifa_x[\"时间\"].apply(lambda x:int(x.split(\" \")[1].split(\":\")[0]))\n",
    "test_2_shifa_x=test_2_shifa_x.drop([\"时间\"],axis=1)\n",
    "test_2[\"实发辐照度\"]=0\n",
    "test_2_shifa_y=test_2.pop(\"实发辐照度\")\n",
    "\n",
    "test_2_shifa_y=LGBModel(train_2_shifa_x,train_2_shifa_y,test_2_shifa_x,test_2_shifa_y)\n",
    "test_2[\"实发辐照度\"]=test_2_shifa_y\n",
    "\n",
    "\n",
    "#特征工程\n",
    "\n",
    "\n",
    "train_2_y=train_2_new.pop(\"实际功率\")\n",
    "train_2_feature1=FeatureCreation1(train_2_new)\n",
    "train_2_feature2=FeatureCreation2(train_2_feature1)\n",
    "train_2_feature3=FeatureCreation3(train_2_feature2)\n",
    "test_2_id=test_2.pop(\"id\")\n",
    "test_2_feature1=FeatureCreation1(test_2)\n",
    "test_2_feature2=FeatureCreation2(test_2_feature1)\n",
    "test_2_feature3=FeatureCreation3(test_2_feature2)\n",
    "\n",
    "train_2_feature3=train_2_feature3.reset_index().drop([\"index\"],axis=1)\n",
    "train_2_y=train_2_y.reset_index().drop([\"index\"],axis=1)\n",
    "train_2_y[\"day\"]=train_2_feature3.pop(\"day\")\n",
    "train_2_feature3=train_2_feature3.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#模型优化\n",
    "\n",
    "#xgb_params = [{\"learning_rate\": [0.01,0.02, 0.05, 0.1, 0.3, 1.0]}, \n",
    "#              {\"reg_lambda\":[0.05,0.1,1,2,10]},\n",
    "#              {\"n_estimators\": [100, 150,200,250,300, 400,500]}, \n",
    "#              {\"max_depth\": range(3,10,2)}, \n",
    "#              {\"min_child_weight\": range(1,6,1)}, \n",
    "#              {\"gamma\": [i/10.0 for i in range(0,5)]}, \n",
    "#              {\"subsample\": [i/10.0 for i in range(6,10)]},\n",
    "#              {\"colsample_bytree\": [i/10.0 for i in range(5,10)]}, \n",
    "#              {\"reg_alpha\": [1e-5, 1e-2, 0.1, 100]}]\n",
    "#xgb_best_params_2 = ModelOptimization(XGBRegressor(), xgb_params,train_2_feature3,train_2_y[\"实际功率\"])\n",
    "\n",
    "\n",
    "\n",
    "#模型评估\n",
    "\n",
    "\n",
    "train_2_x,test_2_x,train_2_y_new,test_2_y=train_test_split(train_2_feature3,train_2_y,test_size=0.2,random_state=0)\n",
    "xgb2 = XGBRegressor(n_estimators = 100, learning_rate = 0.1, max_depth = 7, min_child_weight = 1, \n",
    "                    gamma = 0.1, subsample = 0.8, colsample_bytree = 0.8, reg_alpha = 1e-05)\n",
    "xgb2.fit(train_2_x,train_2_y_new[\"实际功率\"])\n",
    "y_pred2=xgb2.predict(test_2_x)\n",
    "xgb_mae_score_2= scorey(y_pred2,test_2_y,\"station_2\")\n",
    "xgb_mae_score_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce834f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "站点三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据探索\n",
    "\n",
    "#DataExploration(train_3)\n",
    "#DataExploration2(train_3)\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "train_3_new=DataProcessing1(train_3,\"station_3\")\n",
    "#预测实发辐照度\n",
    "train_3_shifa_x=train_3_new[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "train_3_shifa_x[\"month\"]=train_3_shifa_x[\"时间\"].apply(lambda x: int(x.split(\" \")[0].split(\"-\")[1]))\n",
    "train_3_shifa_x[\"hour\"]=train_3_shifa_x[\"时间\"].apply(lambda x:int(x.split(\" \")[1].split(\":\")[0]))\n",
    "train_3_shifa_x=train_3_shifa_x.drop([\"时间\"],axis=1)\n",
    "train_3_shifa_y=train_3_new[\"实发辐照度\"]\n",
    "\n",
    "test_3_shifa_x=test_3[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "test_3_shifa_x[\"month\"]=test_3_shifa_x[\"时间\"].apply(lambda x: int(x.split(\" \")[0].split(\"-\")[1]))\n",
    "test_3_shifa_x[\"hour\"]=test_3_shifa_x[\"时间\"].apply(lambda x:int(x.split(\" \")[1].split(\":\")[0]))\n",
    "test_3_shifa_x=test_3_shifa_x.drop([\"时间\"],axis=1)\n",
    "test_3[\"实发辐照度\"]=0\n",
    "test_3_shifa_y=test_3.pop(\"实发辐照度\")\n",
    "\n",
    "test_3_shifa_y=LGBModel(train_3_shifa_x,train_3_shifa_y,test_3_shifa_x,test_3_shifa_y)\n",
    "test_3[\"实发辐照度\"]=test_3_shifa_y\n",
    "\n",
    "\n",
    "#特征工程\n",
    "\n",
    "\n",
    "train_3_y=train_3_new.pop(\"实际功率\")\n",
    "train_3_feature1=FeatureCreation1(train_3_new)\n",
    "train_3_feature2=FeatureCreation2(train_3_feature1)\n",
    "train_3_feature3=FeatureCreation3(train_3_feature2)\n",
    "test_3_id=test_3.pop(\"id\")\n",
    "test_3_feature1=FeatureCreation1(test_3)\n",
    "test_3_feature2=FeatureCreation2(test_3_feature1)\n",
    "test_3_feature3=FeatureCreation3(test_3_feature2)\n",
    "\n",
    "train_3_feature3=train_3_feature3.reset_index().drop([\"index\"],axis=1)\n",
    "train_3_y=train_3_y.reset_index().drop([\"index\"],axis=1)\n",
    "train_3_y[\"day\"]=train_3_feature3.pop(\"day\")\n",
    "train_3_feature3=train_3_feature3.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#模型优化\n",
    "\n",
    "#xgb_params = [{\"learning_rate\": [0.01,0.02, 0.05, 0.1, 0.3, 1.0]}, \n",
    "#              {\"reg_lambda\":[0.05,0.1,1,2,10]},\n",
    "#              {\"n_estimators\": [100, 150,200,250,300, 400,500]}, \n",
    "#              {\"max_depth\": range(3,10,2)}, \n",
    "#              {\"min_child_weight\": range(1,6,1)}, \n",
    "#              {\"gamma\": [i/10.0 for i in range(0,5)]}, \n",
    "#              {\"subsample\": [i/10.0 for i in range(6,10)]},\n",
    "#              {\"colsample_bytree\": [i/10.0 for i in range(5,10)]}, \n",
    "#              {\"reg_alpha\": [1e-5, 1e-2, 0.1, 100]}]\n",
    "#xgb_best_params_3 = ModelOptimization(XGBRegressor(), xgb_params,train_3_feature3,train_3_y[\"实际功率\"])\n",
    "\n",
    "\n",
    "\n",
    "#模型评估\n",
    "\n",
    "\n",
    "train_3_x,test_3_x,train_3_y_new,test_3_y=train_test_split(train_3_feature3,train_3_y,test_size=0.2,random_state=0)\n",
    "xgb3 = XGBRegressor(n_estimators = 100, learning_rate = 0.05, max_depth = 9, min_child_weight = 4, \n",
    "                    gamma = 0.4, subsample = 0.9, colsample_bytree = 0.9, reg_alpha = 100)\n",
    "xgb3.fit(train_3_x,train_3_y_new[\"实际功率\"])\n",
    "y_pred3=xgb3.predict(test_3_x)\n",
    "xgb_mae_score_3= scorey(y_pred3,test_3_y,\"station_3\")\n",
    "xgb_mae_score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc39afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "站点四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据探索\n",
    "\n",
    "#DataExploration(train_4)\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "train_4_new=DataProcessing1(train_4,\"station_4\")\n",
    "#预测实发辐照度\n",
    "train_4_shifa_x=train_4_new[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "train_4_shifa_x[\"month\"]=train_4_shifa_x[\"时间\"].apply(lambda x: int(x.split(\" \")[0].split(\"-\")[1]))\n",
    "train_4_shifa_x[\"hour\"]=train_4_shifa_x[\"时间\"].apply(lambda x:int(x.split(\" \")[1].split(\":\")[0]))\n",
    "train_4_shifa_x=train_4_shifa_x.drop([\"时间\"],axis=1)\n",
    "train_4_shifa_y=train_4_new[\"实发辐照度\"]\n",
    "\n",
    "test_4_shifa_x=test_4[['辐照度', '风速','风向', '温度',  '压强','湿度', '时间']]\n",
    "test_4_shifa_x[\"month\"]=test_4_shifa_x[\"时间\"].apply(lambda x: int(x.split(\" \")[0].split(\"-\")[1]))\n",
    "test_4_shifa_x[\"hour\"]=test_4_shifa_x[\"时间\"].apply(lambda x:int(x.split(\" \")[1].split(\":\")[0]))\n",
    "test_4_shifa_x=test_4_shifa_x.drop([\"时间\"],axis=1)\n",
    "test_4[\"实发辐照度\"]=0\n",
    "test_4_shifa_y=test_4.pop(\"实发辐照度\")\n",
    "\n",
    "test_4_shifa_y=LGBModel(train_4_shifa_x,train_4_shifa_y,test_4_shifa_x,test_4_shifa_y)\n",
    "test_4[\"实发辐照度\"]=test_4_shifa_y\n",
    "\n",
    "\n",
    "#特征工程\n",
    "\n",
    "\n",
    "train_4_y=train_4_new.pop(\"实际功率\")\n",
    "train_4_feature1=FeatureCreation1(train_4_new)\n",
    "train_4_feature2=FeatureCreation2(train_4_feature1)\n",
    "train_4_feature3=FeatureCreation3(train_4_feature2)\n",
    "test_4_id=test_4.pop(\"id\")\n",
    "test_4_feature1=FeatureCreation1(test_4)\n",
    "test_4_feature2=FeatureCreation2(test_4_feature1)\n",
    "test_4_feature3=FeatureCreation3(test_4_feature2)\n",
    "\n",
    "train_4_feature3=train_4_feature3.reset_index().drop([\"index\"],axis=1)\n",
    "train_4_y=train_4_y.reset_index().drop([\"index\"],axis=1)\n",
    "train_4_y[\"day\"]=train_4_feature3.pop(\"day\")\n",
    "train_4_feature3=train_4_feature3.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#xgb_params = [{\"learning_rate\": [0.01,0.02, 0.05, 0.1, 0.3, 1.0]}, \n",
    "#              {\"reg_lambda\":[0.05,0.1,1,2,10]},\n",
    "#              {\"n_estimators\": [100, 150,200,250,300, 400,500]}, \n",
    "#              {\"max_depth\": range(3,10,2)}, \n",
    "#              {\"min_child_weight\": range(1,6,1)}, \n",
    "#              {\"gamma\": [i/10.0 for i in range(0,5)]}, \n",
    "#              {\"subsample\": [i/10.0 for i in range(6,10)]},\n",
    "#              {\"colsample_bytree\": [i/10.0 for i in range(5,10)]}, \n",
    "#              {\"reg_alpha\": [1e-5, 1e-2, 0.1, 100]}]\n",
    "#xgb_best_params_4 = ModelOptimization(XGBRegressor(), xgb_params,train_4_feature3,train_4_y[\"实际功率\"])\n",
    "\n",
    "\n",
    "\n",
    "train_4_x,test_4_x,train_4_y_new,test_4_y=train_test_split(train_4_feature3,train_4_y,test_size=0.2,random_state=0)\n",
    "xgb4 = XGBRegressor(n_estimators = 100, learning_rate = 0.05, max_depth = 9, min_child_weight = 4, \n",
    "                    gamma = 0.4, subsample = 0.9, colsample_bytree = 0.9, reg_alpha = 100)\n",
    "xgb4.fit(train_4_x,train_4_y_new[\"实际功率\"])\n",
    "y_pred4=xgb4.predict(test_4_x)\n",
    "xgb_mae_score_4= scorey(y_pred4,test_4_y,\"station_4\")\n",
    "xgb_mae_score_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_feature3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "拟合预测并生成结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2098b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_feature3=test_1_feature3.drop([\"day\"],axis=1)\n",
    "test_2_feature3=test_2_feature3.drop([\"day\"],axis=1)\n",
    "test_3_feature3=test_3_feature3.drop([\"day\"],axis=1)\n",
    "test_4_feature3=test_4_feature3.drop([\"day\"],axis=1)\n",
    "cols=['辐照度', '风速', '风向', '温度', '压强', '湿度', '实发辐照度', 'hour', 'month', '白天', '辐照度_mean', '辐照度_std', '辐照度_max', '辐照度_min', '辐照度_白天差', '温度_mean', '温度_std', '温度_max', '温度_min', '温度_白天差', '湿度_mean', '湿度_std', '湿度_max', '湿度_min', '湿度_白天差', '压强_mean', '压强_std', '压强_max', '压强_min', '压强_白天差', 'temp_split', 'pres_split', 'humi_split', 'H_split', 'sin_wind_d', 'cos_wind_d', 'temp_pressure', 'temp_humi', 'before_f', 'before_f1', 'before_f2', 'temp_before_f', 'temp_before_f1', 'temp_before_f2', 'humi_before_f', 'humi_before_f1', 'humi_before_f2', 'irr_before_f', 'irr_before_f1', 'irr_before_f2', 'speed_before_f', 'spedd_before_f1', 'speed_before_f2']\n",
    "\n",
    "test_2_feature3=test_2_feature3.loc[:,cols]\n",
    "test_3_feature3=test_3_feature3.loc[:,cols]\n",
    "test_4_feature3=test_4_feature3.loc[:,cols]\n",
    "\n",
    "y_pred1=xgb.predict(test_1_feature3)\n",
    "y_pred2 =xgb2.predict(test_2_feature3)\n",
    "y_pred3 =xgb3.predict(test_3_feature3)\n",
    "y_pred4 =xgb4.predict(test_4_feature3)\n",
    "\n",
    "y1_sub=pd.DataFrame({\"id\":list(test_1_id),\"predicition\":list(y_pred1)})\n",
    "y2_sub=pd.DataFrame({\"id\":list(test_2_id),\"predicition\":list(y_pred2)})\n",
    "y3_sub=pd.DataFrame({\"id\":list(test_3_id),\"predicition\":list(y_pred3)})\n",
    "y4_sub=pd.DataFrame({\"id\":list(test_4_id),\"predicition\":list(y_pred4)})\n",
    "submission=pd.concat([y1_sub,y2_sub,y3_sub,y4_sub],axis=0).set_index([\"id\"])\n",
    "submission.to_csv(\"../Submission/Submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6.2_jupy",
   "language": "python",
   "name": "python3.6.2_jupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
